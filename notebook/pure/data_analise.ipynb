{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "## Content\n",
    "  * Load data \n",
    "  * Investigate SalePrice\n",
    "  * Remove bad fields\n",
    "  * Dealing with missing data\n",
    "  * Correlation matrix for numerical features\n",
    "  * Encode categorical features to numerical\n",
    "  * Correlation matrix for encoded categorical features\n",
    "  * Investigate Logarifm transformations\n",
    "  * Investigate Pow transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from pymongo import MongoClient\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGODB_URL = os.environ['AMES_MONGODB_URI']\n",
    "client = MongoClient(MONGODB_URL)\n",
    "db = client.get_default_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db[\"train_data\"].find({})\n",
    "df_train = pd.DataFrame(list(data))\n",
    "df_train.drop(columns=[\"_id\"], inplace=True)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db[\"test_data\"].find({})\n",
    "df_test = pd.DataFrame(list(data))\n",
    "df_test.drop(columns=[\"_id\"], inplace=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_frame = pd.concat([df_train, df_test])\n",
    "full_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram\n",
    "sns.set(rc={'figure.figsize':(15,5)})\n",
    "fig, ax = plt.subplots(1,2)\n",
    "sns.distplot(np.log1p(full_frame['SalePrice']), fit=norm, ax=ax[0])\n",
    "sns.distplot(full_frame['SalePrice'], fit=norm, ax=ax[1])\n",
    "ax[0].set_title(\"SalePrice: after logarithm transform\")\n",
    "ax[1].set_title(\"SalePrice: original\")\n",
    "fig.show()\n",
    "\n",
    "#normal probability plot\n",
    "fig, ax = plt.subplots(1,2)\n",
    "stats.probplot(np.log1p(full_frame['SalePrice']), plot=ax[0])\n",
    "stats.probplot(full_frame['SalePrice'], plot=ax[1])\n",
    "ax[0].set_title(\"SalePrice: after logarithm transform\")\n",
    "ax[1].set_title(\"SalePrice: original\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should choose True value for applyLogTransformForSalePrice if after logarithm transform SalePrice became more corresponded with normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applyLogTransformForSalePrice = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if applyLogTransformForSalePrice:\n",
    "    full_frame['SalePrice'] = np.log1p(full_frame['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bad fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(full_frame.columns.tolist())\n",
    "features.remove('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose fields that cannot be taken for training for some reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.remove('OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = full_frame.isnull().sum().sort_values(ascending=False)\n",
    "percent = (full_frame.isnull().sum()/full_frame.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove features where data is missed more then 5 times\n",
    "features = features.difference(set((missing_data[missing_data['Total'] > 5]).index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove left images where data is missed\n",
    "full_frame = full_frame.drop(full_frame.loc[full_frame.isnull().any(axis=1)].index)\n",
    "full_frame[list(features)].isnull().sum().max() #just checking that there's no missing data missing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features left\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get categorical features list\n",
    "g = {k.name: v for k, v in full_frame[list(features)].columns.to_series().groupby(full_frame.dtypes).groups.items()}\n",
    "categorical = g[\"object\"].tolist()\n",
    "numerical = g[\"float64\"].tolist() + g[\"int64\"].tolist()\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical features list\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = full_frame[numerical + ['SalePrice']].copy(True)\n",
    "\n",
    "#correlation matrix\n",
    "corrmat = numerical_df.corr().abs()\n",
    "\n",
    "# sort columns in df by SalePrice correlation\n",
    "cols = corrmat.sort_values([\"SalePrice\"])['SalePrice'].index\n",
    "# get new correlation matrix with sorted columns\n",
    "cm = numerical_df[cols].corr().abs()\n",
    "# show plot\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "sns.heatmap(cm, vmax=.8, square=True, yticklabels=cols.values, xticklabels=cols.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with features which highly correlated with each other\n",
    "# features that correlated with each other more then this threshold should be considered to remove\n",
    "# Please enter threshold\n",
    "thresh = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask to go through only under diagonal triangle\n",
    "mask = np.ones(cm.shape,dtype='bool')\n",
    "mask[np.triu_indices(len(cm))] = False\n",
    "\n",
    "highly_corr_cm = cm.drop(index=['SalePrice'],columns=['SalePrice'])[(cm>thresh)&mask].dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "highly_corr_cm = highly_corr_cm.append(cm['SalePrice'][highly_corr_cm.columns])\n",
    "highly_corr_cm['SalePrice'] = cm['SalePrice'][highly_corr_cm.index]\n",
    "highly_corr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter features that should be removed according to table above \n",
    "columns_to_remove = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df.drop(columns=columns_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define attributes with highest correlation and transformation type which should be applied for it. Please enter wished correlation threshold for numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_threshold_for_num_features = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df_log = numerical_df.copy(True)\n",
    "numerical_df_log.drop(columns=['SalePrice'], inplace=True)\n",
    "for feature in numerical_df_log.columns:\n",
    "    numerical_df_log[feature] = numerical_df_log[feature].apply(lambda x: 0 if x <= 1 else np.log(x))\n",
    "numerical_df_log[\"SalePrice\"] = numerical_df[\"SalePrice\"]\n",
    "corrmat_log = numerical_df_log.corr().abs()\n",
    "\n",
    "\n",
    "numerical_df_pow = numerical_df.copy(True)\n",
    "numerical_df_pow = numerical_df_pow.drop(columns=['SalePrice']).apply(lambda x: x**2)\n",
    "numerical_df_pow[\"SalePrice\"] = numerical_df[\"SalePrice\"]\n",
    "corrmat_pow = numerical_df_pow.corr().abs()\n",
    "\n",
    "magic_num_table = pd.DataFrame()\n",
    "magic_num_table[\"log\"] = corrmat_log[\"SalePrice\"]\n",
    "magic_num_table[\"pow\"] = corrmat_pow[\"SalePrice\"]\n",
    "magic_num_table[\"origin\"] = corrmat[\"SalePrice\"]\n",
    "magic_num_table[\"highest_value\"] = magic_num_table.max(axis=1)\n",
    "\n",
    "magic_num_table[\"transform_type\"] = \"magic_num_table\"\n",
    "magic_num_table[\"transform_type\"][magic_num_table[\"log\"] == magic_num_table[\"highest_value\"]] = \"log\"\n",
    "magic_num_table[\"transform_type\"][magic_num_table[\"pow\"] == magic_num_table[\"highest_value\"]] = \"pow\"\n",
    "magic_num_table[\"transform_type\"][magic_num_table[\"origin\"] == magic_num_table[\"highest_value\"]] = \"origin\"\n",
    "\n",
    "magic_num_table.drop(index=[\"SalePrice\"], inplace=True)\n",
    "\n",
    "magic_num_table = magic_num_table.sort_values('origin', ascending=False)\n",
    "magic_num_table = magic_num_table[magic_num_table[\"origin\"] > corr_threshold_for_num_features]\n",
    "magic_num_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "magic_num_table[\"transform_type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical features to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features list\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform ANOVA test \n",
    "\n",
    "def anova(frame, qualitative):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['feature'] = qualitative\n",
    "    pvals = []\n",
    "    for c in qualitative:\n",
    "        samples = []\n",
    "        for cls in frame[c].unique():\n",
    "            s = frame[frame[c] == cls]['SalePrice'].values\n",
    "            samples.append(s.astype(np.float64))\n",
    "        pval = stats.f_oneway(*samples)[1]\n",
    "        pvals.append(pval)\n",
    "    anv['pval'] = pvals\n",
    "    return anv.sort_values('pval')\n",
    "\n",
    "a = anova(full_frame.copy(True), g[\"object\"].tolist())\n",
    "a['disparity'] = np.log(1./a['pval'].values)\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "sns.barplot(data=a, y='feature', x='disparity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform encoding\n",
    "\n",
    "dummies = {}\n",
    "\n",
    "def encode(frame, feature):\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n",
    "    ordering = ordering.sort_values('spmean')\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1)\n",
    "    ordering = ordering['ordering'].to_dict()\n",
    "    \n",
    "    for cat, o in ordering.items():\n",
    "        frame.loc[frame[feature] == cat, feature] = o\n",
    "    \n",
    "    return ordering\n",
    "    \n",
    "for c in categorical:  \n",
    "    dummies[c] = encode(full_frame, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df = full_frame[categorical + ['SalePrice']]\n",
    "categorical_df['SalePrice'] = np.log1p(categorical_df['SalePrice'])\n",
    "\n",
    "#correlation matrix\n",
    "corrmat = categorical_df.corr().abs()\n",
    "cols = corrmat.sort_values([\"SalePrice\"])['SalePrice'].index\n",
    "cm = categorical_df[cols].corr().abs()\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "sns.heatmap(cm, vmax=.8, square=True, yticklabels=cols.values, xticklabels=cols.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(cm.shape,dtype='bool')\n",
    "mask[np.triu_indices(len(cm))] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with features which highly correlated with each other\n",
    "# features that correlated with each other more then this threshold should be considered to remove\n",
    "# Please enter threshold\n",
    "thresh = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_corr_cm = cm.drop(index=['SalePrice'],columns=['SalePrice'])[(cm>thresh)&mask].dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "highly_corr_cm = highly_corr_cm.append(cm['SalePrice'][highly_corr_cm.columns])\n",
    "highly_corr_cm['SalePrice'] = cm['SalePrice'][highly_corr_cm.index]\n",
    "highly_corr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please enter features that should be removed according to table above \n",
    "columns_to_remove = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df.drop(columns=columns_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define attributes with highest correlation and transformation type which should be applied for it. Please enter wished correlation threshold for categorical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_threshold_for_cat_features = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_df_log = categorical_df.copy(True)\n",
    "categorical_df_log = categorical_df_log.drop(columns=['SalePrice']).apply(lambda x: np.log1p(x))\n",
    "categorical_df_log[\"SalePrice\"] = categorical_df[\"SalePrice\"]\n",
    "corrmat_log = categorical_df_log.corr().abs()\n",
    "\n",
    "categorical_df_pow = categorical_df.copy(True)\n",
    "categorical_df_pow = categorical_df_pow.drop(columns=['SalePrice']).apply(lambda x: x**2)\n",
    "categorical_df_pow[\"SalePrice\"] = categorical_df[\"SalePrice\"]\n",
    "corrmat_pow = categorical_df_pow.corr().abs()\n",
    "\n",
    "magic_cat_table = pd.DataFrame()\n",
    "magic_cat_table[\"log\"] = corrmat_log[\"SalePrice\"]\n",
    "magic_cat_table[\"pow\"] = corrmat_pow[\"SalePrice\"]\n",
    "magic_cat_table[\"origin\"] = corrmat[\"SalePrice\"]\n",
    "magic_cat_table[\"highest_value\"] = magic_cat_table.max(axis=1)\n",
    "\n",
    "magic_cat_table[\"transform_type\"] = \"magic_cat_table\"\n",
    "magic_cat_table[\"transform_type\"][magic_cat_table[\"log\"] == magic_cat_table[\"highest_value\"]] = \"log\"\n",
    "magic_cat_table[\"transform_type\"][magic_cat_table[\"pow\"] == magic_cat_table[\"highest_value\"]] = \"pow\"\n",
    "magic_cat_table[\"transform_type\"][magic_cat_table[\"origin\"] == magic_cat_table[\"highest_value\"]] = \"origin\"\n",
    "\n",
    "magic_cat_table.drop(index=[\"SalePrice\"], inplace=True)\n",
    "\n",
    "magic_cat_table = magic_cat_table.sort_values('origin', ascending=False)\n",
    "magic_cat_table = magic_cat_table[magic_cat_table[\"origin\"] > corr_threshold_for_cat_features]\n",
    "magic_cat_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "magic_cat_table[\"transform_type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_table = pd.concat([magic_cat_table, magic_num_table]).sort_values('origin', ascending=False)\n",
    "magic_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation proofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if applyLogTransformForSalePrice:\n",
    "    full_frame['SalePrice'] = np.expm1(full_frame['SalePrice'])\n",
    "features = magic_table.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logarifm transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logarifm_frame = full_frame[features + ['SalePrice']].copy(True)\n",
    "for feature in logarifm_frame.columns:\n",
    "    logarifm_frame[feature] = logarifm_frame[feature].apply(lambda x: 0 if x <= 1 else np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,5)})\n",
    "for feature in features:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    stats.probplot(logarifm_frame[feature], plot=ax[0])\n",
    "    stats.probplot(full_frame[feature], plot=ax[1])\n",
    "    ax[0].set_title(feature + \": after logarithm transform\")\n",
    "    ax[1].set_title(feature + \": original\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pow transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_frame = full_frame[features + ['SalePrice']].copy(True)\n",
    "for feature in logarifm_frame.columns:\n",
    "    pow_frame[feature] = pow_frame[feature].apply(lambda row: row**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15,5)})\n",
    "for feature in features:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    stats.probplot(pow_frame[feature], plot=ax[0])\n",
    "    stats.probplot(full_frame[feature], plot=ax[1])\n",
    "    ax[0].set_title(feature + \": after pow transform\")\n",
    "    ax[1].set_title(feature + \": original\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results for future learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_collection = db[\"notebook\"]\n",
    "notebook_collection.remove({})\n",
    "notebook_collection.insert_many(full_frame.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
